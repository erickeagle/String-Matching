{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44OAr7FgxyKK"
   },
   "source": [
    "# String Matching on Large Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's very difficult to  deal with the large dataset for match the string with the traditional libraries like Fuzzy Wuzzy, ftfy,Levenshtein,etc. For example, We are matching from two file each having 10k entries then if we want to perform string matching between two columns of each files, taking only 100 entries from first file and second file is consumed fully and store the percent similarity and matched entry on the first file. Then for Fuzzy-Wuzzy,if it took 15 seconds in my system (Configuration of my system is i7 8th generation processor having 8 GB Ram and 4 GB Nvidia GeForce GTX 1050ti.), when I am utilizing the GPU. If we take whole file then the consumed is approx is 1500 seconds and if our data is lakhs then the time consumed is much high.<br> \n",
    "Then in place of Fuzzy-Wuzzy we can match the strings using the NLP Algorithm which is based on n-grams and tf-idf which can match both the file in one go in appox 8-10 sec. Which is really-really fast than any other string matching package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing some Important pakages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "Bjon4p9R72o3",
    "outputId": "f579771b-6d01-469b-cf95-afd4893c59ec"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from ftfy import fix_text\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZmlhiE9jvdr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LINE_NO</th>\n",
       "      <th>ENGL_CUST_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>25475066</td>\n",
       "      <td>Lee Siu Lam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>27634906</td>\n",
       "      <td>Chiu Siu Ying Betty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>27155866</td>\n",
       "      <td>Lee Chi Pang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>27740669</td>\n",
       "      <td>Wong Yuk Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>24408814</td>\n",
       "      <td>Chow Kwok Leung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>10995</td>\n",
       "      <td>23321078</td>\n",
       "      <td>Hang Feng (HK) Co Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>10996</td>\n",
       "      <td>26546388</td>\n",
       "      <td>Eleven Lounge &amp; Rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>10997</td>\n",
       "      <td>21647388</td>\n",
       "      <td>Eleven Lounge &amp; Rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>10998</td>\n",
       "      <td>23983136</td>\n",
       "      <td>Hk Great Wealth Internatl Trdg Co Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10999</td>\n",
       "      <td>26318121</td>\n",
       "      <td>Xh Internatl Greative Group Co Ltd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   LINE_NO                         ENGL_CUST_NAME\n",
       "0           1000  25475066                            Lee Siu Lam\n",
       "1           1001  27634906                    Chiu Siu Ying Betty\n",
       "2           1002  27155866                           Lee Chi Pang\n",
       "3           1003  27740669                           Wong Yuk Sim\n",
       "4           1004  24408814                        Chow Kwok Leung\n",
       "...          ...       ...                                    ...\n",
       "9995       10995  23321078                  Hang Feng (HK) Co Ltd\n",
       "9996       10996  26546388                   Eleven Lounge & Rest\n",
       "9997       10997  21647388                   Eleven Lounge & Rest\n",
       "9998       10998  23983136  Hk Great Wealth Internatl Trdg Co Ltd\n",
       "9999       10999  26318121     Xh Internatl Greative Group Co Ltd\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the first file\n",
    "data_1 =  pd.read_csv('data_1.csv',encoding='latin')\n",
    "data_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngrams \n",
    "ngrmas is basically continous sequencing of n items for a given sample of text or speech.<br>\n",
    "For example-<br>\n",
    "Taking, ngrams = 3<br>\n",
    "For the word **Data**, the sequence generated is **' Da', 'Dat', 'ata', 'ta '**. which are used for string matching.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "w8nlYCUq8Ge6",
    "outputId": "4f6a0582-d888-43a6-e70d-688d2fac3ddb"
   },
   "outputs": [],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "def ngram(string, n=3):\n",
    "    s = fix_text(string) # fix text\n",
    "    s = s.encode(\"ascii\", errors=\"ignore\").decode() #remove non ascii chars\n",
    "    s = s.lower()\n",
    "    chars_to_remove = [\")\",\"(\",\".\",\"|\",\"[\",\"]\",\"{\",\"}\",\"'\"]\n",
    "    rx = '[' + re.escape(''.join(chars_to_remove)) + ']'\n",
    "    s = re.sub(rx, '', string)\n",
    "    s= s.replace('&', 'and')\n",
    "    s = s.replace(',', ' ')\n",
    "    s = s.replace('-', ' ')\n",
    "    s = s.title() # normalise case - capital at start of each word\n",
    "    s = re.sub(' +',' ',s).strip() # get rid of multiple spaces and replace with a single\n",
    "    s = ' '+ s +' ' # pad names for ngrams...\n",
    "    s = re.sub(r'[,-./]|\\sBD',r'', s)\n",
    "    ng = zip(*[s[i:] for i in range(n)])\n",
    "    return [''.join(ng1) for ng1 in ng]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf (Term frequency and Inverse document frequency)\n",
    "The aim of tf-idf is to define the importance of a keyword or phrase within a document or a web page and we can add ngram function as a analyzer in the tfidf vectorizer which generated the sequence of each entries then a sparse matrix is generated, which is used to find the percent similarity of the strings.This algorithms usually deal with numbers, and natural language is, well, text and it transform that text into numbers. Vectorizing a document is taking the text and creating one of these vectors, and the numbers of the vectors somehow represent the content of the text. TF-IDF enables us to gives us a way to associate each word in a document with a number that represents how relevant each word is in that document.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Term Frequency** is simply the raw count of a term in a document or the number of times a word occurs in the document. There are ways to adjust the frequency, by length of a document, or by the raw frequency of the most frequent word in a document.\n",
    "- **Inverse document frequency** is the measure of how much information the word provides, i.e., if it's common or rare across all documents. The closer it is to 0, the more common a word is. This metric can be calculated by taking the total number of documents, dividing it by the number of documents that contain a word, and calculating the logarithm.\n",
    "- So, if the word is very common and appears in many documents, this number will approach 0. Otherwise, it will approach 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplying these two numbers results in the TF-IDF score of a word in a document. The higher the score, the more relevant that word is in that particular document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applications of TF-IDF**\n",
    "- Information retrieval\n",
    "- Keyword Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "xo-X_nds97UN",
    "outputId": "db756e79-9ba8-40bc-8749-b9bbfaeaaa64"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CUST_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>LEE TAI TRANSPORT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>WAI YIP MAINTENANCE ENGINEERING LTD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>SANFIELD-GAMMON CONSTRUCTION JV COMPANY LIMITED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>ASMAC LIMITED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>268 HAIR SALOON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>10995</td>\n",
       "      <td>COPPERBURG DEVELOPMENT LTD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>10996</td>\n",
       "      <td>LUK HUP PLASTIC MATERIACS CO.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>10997</td>\n",
       "      <td>KI MEE KITCHEWARE LTD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>10998</td>\n",
       "      <td>LEE TAK GROCERY COMPANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10999</td>\n",
       "      <td>NICEWORK CONSTRUCTION ENGINEERING LIMITED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                        CUST_NAME\n",
       "0           1000                                LEE TAI TRANSPORT\n",
       "1           1001              WAI YIP MAINTENANCE ENGINEERING LTD\n",
       "2           1002  SANFIELD-GAMMON CONSTRUCTION JV COMPANY LIMITED\n",
       "3           1003                                    ASMAC LIMITED\n",
       "4           1004                                  268 HAIR SALOON\n",
       "...          ...                                              ...\n",
       "9995       10995                       COPPERBURG DEVELOPMENT LTD\n",
       "9996       10996                    LUK HUP PLASTIC MATERIACS CO.\n",
       "9997       10997                            KI MEE KITCHEWARE LTD\n",
       "9998       10998                          LEE TAK GROCERY COMPANY\n",
       "9999       10999        NICEWORK CONSTRUCTION ENGINEERING LIMITED\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer as TV\n",
    "#Loding the second dataset\n",
    "data_2 = pd.read_csv('data_2.csv')\n",
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "Xwdfl4Gtqwet",
    "outputId": "2f98ddf7-6d4d-468e-d8ff-7fd14164b367"
   },
   "outputs": [],
   "source": [
    "\n",
    "new_data_2 = data_2['CUST_NAME'].values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FSbSr_pNzAc4"
   },
   "source": [
    " **Vecorizing the data**\n",
    "<br>While vectorizing the data, we are going to use the lowercase as false and using ngram as the analyser and then fit transform the data of the second file in a sparse matrix which is used for matching the ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TV(min_df=1, analyzer=ngram, lowercase=False)\n",
    "tfidf = vectorizer.fit_transform(new_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using KNN** for finding or matching the nearest neighours of each string of file one with the vectorized matrix of second file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "NN = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(tfidf)\n",
    "data_1_new = (data_1['ENGL_CUST_NAME'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearestNeigh(query):\n",
    "  query_1= vectorizer.transform(query)\n",
    "  distances, indices = NN.kneighbors(query_1)\n",
    "  return distances, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculati the distance and indices of each strings of the file one and then enumerating over the indices for finding the closest match of each entry of file one from the file 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Consumed for matching using ngrams and tfidf is  8.168980836868286\n"
     ]
    }
   ],
   "source": [
    "distances, indices = getNearestNeigh(data_1_new)\n",
    "#unique_org = list(data_1_new) #need to convert back to a list\n",
    "#print('finding matches...')\n",
    "final = []\n",
    "for i,j in enumerate(indices):\n",
    "    dist=round(distances[i][0],2)\n",
    "    temp = [dist, data_2.values[j][0][1]]\n",
    "    final.append(temp)\n",
    "t = time.time()-t1\n",
    "print(\"Time Consumed for matching using ngrams and tfidf is \", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(final, columns=['Match confidence','Matched name'])\n",
    "data_1['Ratio']=final['Match confidence']\n",
    "data_1['Matched Name']=final['Matched name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### This is the required result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LINE_NO</th>\n",
       "      <th>ENGL_CUST_NAME</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>Matched Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>25475066</td>\n",
       "      <td>Lee Siu Lam</td>\n",
       "      <td>0.83</td>\n",
       "      <td>KWAN SIU LAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>27634906</td>\n",
       "      <td>Chiu Siu Ying Betty</td>\n",
       "      <td>1.10</td>\n",
       "      <td>SIU YUN TING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>27155866</td>\n",
       "      <td>Lee Chi Pang</td>\n",
       "      <td>0.73</td>\n",
       "      <td>KONG CHI PANG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>27740669</td>\n",
       "      <td>Wong Yuk Sim</td>\n",
       "      <td>0.98</td>\n",
       "      <td>NG YUK SANG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>24408814</td>\n",
       "      <td>Chow Kwok Leung</td>\n",
       "      <td>1.04</td>\n",
       "      <td>CHOW KAN WAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>10995</td>\n",
       "      <td>23321078</td>\n",
       "      <td>Hang Feng (HK) Co Ltd</td>\n",
       "      <td>0.91</td>\n",
       "      <td>YU FENG (HK) TRADING CO LTD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>10996</td>\n",
       "      <td>26546388</td>\n",
       "      <td>Eleven Lounge &amp; Rest</td>\n",
       "      <td>1.09</td>\n",
       "      <td>CORNER LOUNGE LTD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>10997</td>\n",
       "      <td>21647388</td>\n",
       "      <td>Eleven Lounge &amp; Rest</td>\n",
       "      <td>1.09</td>\n",
       "      <td>CORNER LOUNGE LTD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>10998</td>\n",
       "      <td>23983136</td>\n",
       "      <td>Hk Great Wealth Internatl Trdg Co Ltd</td>\n",
       "      <td>1.06</td>\n",
       "      <td>WEALTH INDUSTRY (HK) CO LTD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10999</td>\n",
       "      <td>26318121</td>\n",
       "      <td>Xh Internatl Greative Group Co Ltd</td>\n",
       "      <td>1.03</td>\n",
       "      <td>CHEUNG WO INT'L (GROUP) CO LTD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   LINE_NO                         ENGL_CUST_NAME  Ratio  \\\n",
       "0           1000  25475066                            Lee Siu Lam   0.83   \n",
       "1           1001  27634906                    Chiu Siu Ying Betty   1.10   \n",
       "2           1002  27155866                           Lee Chi Pang   0.73   \n",
       "3           1003  27740669                           Wong Yuk Sim   0.98   \n",
       "4           1004  24408814                        Chow Kwok Leung   1.04   \n",
       "...          ...       ...                                    ...    ...   \n",
       "9995       10995  23321078                  Hang Feng (HK) Co Ltd   0.91   \n",
       "9996       10996  26546388                   Eleven Lounge & Rest   1.09   \n",
       "9997       10997  21647388                   Eleven Lounge & Rest   1.09   \n",
       "9998       10998  23983136  Hk Great Wealth Internatl Trdg Co Ltd   1.06   \n",
       "9999       10999  26318121     Xh Internatl Greative Group Co Ltd   1.03   \n",
       "\n",
       "                        Matched Name  \n",
       "0                       KWAN SIU LAM  \n",
       "1                       SIU YUN TING  \n",
       "2                      KONG CHI PANG  \n",
       "3                        NG YUK SANG  \n",
       "4                       CHOW KAN WAN  \n",
       "...                              ...  \n",
       "9995     YU FENG (HK) TRADING CO LTD  \n",
       "9996               CORNER LOUNGE LTD  \n",
       "9997               CORNER LOUNGE LTD  \n",
       "9998     WEALTH INDUSTRY (HK) CO LTD  \n",
       "9999  CHEUNG WO INT'L (GROUP) CO LTD  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Now using the fuzzy wuzzy algo to perform the above \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned, Fuzzy Wuzzy consume time for matching the string. So, I am using only 100 entries from first file and second file is consumed fully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_copy=data_1.copy().head(100)\n",
    "data_1_copy=list(data1_copy['ENGL_CUST_NAME'])\n",
    "data_2_copy=list(data_2['CUST_NAME'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing the Fuzzy Wuzzy Package**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consumed by Fuzzy Wuzzy for 100 entries: 11.957054615020752\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "save_ratio=[]\n",
    "save_cust=[]\n",
    "final_ratio=[]\n",
    "final_cust=[]\n",
    "count=0\n",
    "save_both=[]\n",
    "for i in range(len(data_1_copy)):\n",
    "    save_ratio=[]\n",
    "    save_cust=[]\n",
    "    save_both=[]\n",
    "    for j in data_2_copy:\n",
    "        Ratio = fuzz.token_sort_ratio(data_1_copy[i],j)\n",
    "        \n",
    "        inter_save=str(Ratio)+\"|\"+j\n",
    "        new_save=list(inter_save.split(\"|\"))\n",
    "\n",
    "        save_both.append(new_save)\n",
    "    if save_both==[]:\n",
    "        final_ratio.append(None)\n",
    "        final_cust.append(None)\n",
    "    elif len(save_both)>0:  \n",
    "        val_1=[int(row[0]) for row in save_both]\n",
    "        save=val_1.index(max(val_1))\n",
    "        ans1=save_both[save]\n",
    "    \n",
    "        final_ratio.append(ans1[0])\n",
    "        final_cust.append(ans1[1])\n",
    "t = time.time()-t1\n",
    "print(\"Time consumed by Fuzzy Wuzzy for 100 entries:\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_copy['Names']=final_cust\n",
    "data1_copy['Ratios']=final_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LINE_NO</th>\n",
       "      <th>ENGL_CUST_NAME</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>Matched Name</th>\n",
       "      <th>Names</th>\n",
       "      <th>Ratios</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>25475066</td>\n",
       "      <td>Lee Siu Lam</td>\n",
       "      <td>0.83</td>\n",
       "      <td>KWAN SIU LAM</td>\n",
       "      <td>LEE SHUK HA</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>27634906</td>\n",
       "      <td>Chiu Siu Ying Betty</td>\n",
       "      <td>1.10</td>\n",
       "      <td>SIU YUN TING</td>\n",
       "      <td>CHOI SUI YING</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>27155866</td>\n",
       "      <td>Lee Chi Pang</td>\n",
       "      <td>0.73</td>\n",
       "      <td>KONG CHI PANG</td>\n",
       "      <td>LEE HUNG PANG</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>27740669</td>\n",
       "      <td>Wong Yuk Sim</td>\n",
       "      <td>0.98</td>\n",
       "      <td>NG YUK SANG</td>\n",
       "      <td>WONG YEUK SZE</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>24408814</td>\n",
       "      <td>Chow Kwok Leung</td>\n",
       "      <td>1.04</td>\n",
       "      <td>CHOW KAN WAN</td>\n",
       "      <td>LEUNG KIN HOP</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1095</td>\n",
       "      <td>27746782</td>\n",
       "      <td>Hilton Fur &amp; Leather (HK) Ltd</td>\n",
       "      <td>1.12</td>\n",
       "      <td>MAN FOOK LEATHER COMPANY LIMITED</td>\n",
       "      <td>GOLDEN LEAT DEV (HK) LTD</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1096</td>\n",
       "      <td>21235961</td>\n",
       "      <td>Hilton Fur &amp; Leather (HK) Ltd</td>\n",
       "      <td>1.12</td>\n",
       "      <td>MAN FOOK LEATHER COMPANY LIMITED</td>\n",
       "      <td>GOLDEN LEAT DEV (HK) LTD</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1097</td>\n",
       "      <td>23471785</td>\n",
       "      <td>Cheng Ho See</td>\n",
       "      <td>0.82</td>\n",
       "      <td>CHENG SEE WING</td>\n",
       "      <td>YEE HING HO</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1098</td>\n",
       "      <td>31516380</td>\n",
       "      <td>Ng Wing Chiu</td>\n",
       "      <td>0.99</td>\n",
       "      <td>NG CHING LAM</td>\n",
       "      <td>CHING YING</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1099</td>\n",
       "      <td>23318803</td>\n",
       "      <td>Tse Pui Kei</td>\n",
       "      <td>1.02</td>\n",
       "      <td>PUI KEE TRADING CO</td>\n",
       "      <td>MUI ON KEI</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0   LINE_NO                 ENGL_CUST_NAME  Ratio  \\\n",
       "0         1000  25475066                    Lee Siu Lam   0.83   \n",
       "1         1001  27634906            Chiu Siu Ying Betty   1.10   \n",
       "2         1002  27155866                   Lee Chi Pang   0.73   \n",
       "3         1003  27740669                   Wong Yuk Sim   0.98   \n",
       "4         1004  24408814                Chow Kwok Leung   1.04   \n",
       "..         ...       ...                            ...    ...   \n",
       "95        1095  27746782  Hilton Fur & Leather (HK) Ltd   1.12   \n",
       "96        1096  21235961  Hilton Fur & Leather (HK) Ltd   1.12   \n",
       "97        1097  23471785                   Cheng Ho See   0.82   \n",
       "98        1098  31516380                   Ng Wing Chiu   0.99   \n",
       "99        1099  23318803                    Tse Pui Kei   1.02   \n",
       "\n",
       "                        Matched Name                     Names Ratios  \n",
       "0                       KWAN SIU LAM               LEE SHUK HA     73  \n",
       "1                       SIU YUN TING             CHOI SUI YING     69  \n",
       "2                      KONG CHI PANG             LEE HUNG PANG     80  \n",
       "3                        NG YUK SANG             WONG YEUK SZE     80  \n",
       "4                       CHOW KAN WAN             LEUNG KIN HOP     71  \n",
       "..                               ...                       ...    ...  \n",
       "95  MAN FOOK LEATHER COMPANY LIMITED  GOLDEN LEAT DEV (HK) LTD     64  \n",
       "96  MAN FOOK LEATHER COMPANY LIMITED  GOLDEN LEAT DEV (HK) LTD     64  \n",
       "97                    CHENG SEE WING               YEE HING HO     78  \n",
       "98                      NG CHING LAM                CHING YING     82  \n",
       "99                PUI KEE TRADING CO                MUI ON KEI     67  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion of above comparision is that using of NLP algorithm for string matching is approximately equal to using of Fuzzy Wuzzy for 100 entries only, which is really very slow. Then it is better to use NLP algorithm for Large dataset, because it is much less time consuming than Fuzzy Wuzzy package.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Fast Fuzzy Matching public.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
