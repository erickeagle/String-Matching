# String-Matching

It's very difficult to deal with the large dataset for match the string with the traditional libraries like Fuzzy Wuzzy, ftfy,Levenshtein,etc. For example, We are matching from two file each having 10k entries then if we want to perform string matching between two columns of each files, taking only 100 entries from first file and second file is consumed fully and store the percent similarity and matched entry on the first file. Then for Fuzzy-Wuzzy,if it took 15 seconds in my system (Configuration of my system is i7 8th generation processor having 8 GB Ram and 4 GB Nvidia GeForce GTX 1050ti.), when I am utilizing the GPU. If we take whole file then the consumed is approx is 1500 seconds and if our data is lakhs then the time consumed is much high.
Then in place of Fuzzy-Wuzzy we can match the strings using the NLP Algorithm which is based on n-grams and tf-idf which can match both the file in one go in appox 8-10 sec. Which is really-really fast than any other string matching package.
